---
template: blog-post
title: From Utility to Empathy - How the Product Craft Evolves in the Age of AI
slug: /blog/product-craft
date: 2025-11-10 09:37
description: The product craft as we know it has evolved dramatically
featuredImage: /assets/product-craft.png
---

[Julie Zhuo](https://www.juliezhuo.com/) wrote something recently that really stuck with me: [*The Thing You Are Expert at Will Be Your Career Downfall*](https://lg.substack.com/p/the-thing-you-are-expert-at-will).

In it, she reminds us that mastery doesn’t vanish when technology evolves — it transforms. My favorite line was this:

> When photography emerged in 1839, French academic painter Paul Delaroche reportedly declared, "From today, painting is dead!"  
> In one sense, Delaroche was right — what died was the careers of those painters who photocopied what they saw.  
> But in the broader sense, Delaroche was dead wrong. Photography unshackled painting from its utilitarian purpose.

That line hit me hard. It made me think about what this shift means for product managers like us. What *utilitarian purpose* of product management should we now let go — and how might AI set us free from it?  

---

## The Utilitarian Purpose of Product

For years, our product craft has been very hands-on. We wrote specs. We organized roadmaps. We triaged bugs. We aligned people across teams and time zones. We ensured that everything — from vision to user story — fit neatly together.

That’s where many of us found our pride and our flow: in the precision, the details, the quiet art of connecting dots between users, engineers, and the business.

All of that work, in essence, served a utilitarian purpose — to make sure engineers could pick up a Jira ticket and start coding right away. They should have prototypes ready. They should understand the “what” and the “why.” They should be able to make tough technical trade-offs on behalf of the customer.

This was the invisible scaffolding that held modern product development together. It *had* to exist. And we PMs were the ones holding it up.

---

## The Unshackling

But now, AI is starting to automate more and more of those utilities.

Engineers can prompt AI to write a PRD based on customer surveys or Mixpanel data. Designers can use tools like Figma Make to generate prototype variations in seconds. Data analysis, once a slow dance with spreadsheets and SQL, can be performed through natural language prompts.

Suddenly, the scaffolding we spent years perfecting can be built by the system itself.

So where do we fit in these days?

It’s tempting to feel replaced. But maybe, like painters freed from copying reality, we’re being unshackled from our utilitarian past. Instead of being the ones who do every task, we become the ones who *design the systems* that do them — and bring human judgment, ethics, and empathy to how those systems learn.

---

## From Doing to Designing

The new craft of product is not about *doing more*. It’s about *designing better*.

* Instead of writing the perfect PRD, we’ll define the parameters of tools that can draft one.  
* Instead of spending hours analyzing data, we’ll design feedback loops that surface insights automatically.  
* Instead of loving to prioritize features ourselves, we’ll love teaching systems *how to prioritize*.  
* Instead of trying to align every person manually, we’ll love aligning *humans and machines* around a shared vision.

It’s a little scary, but also kind of freeing. Because if AI can handle the mechanical side of product work, we finally have more space for the *human* side — the part machines can’t (and shouldn’t) replicate.

---

## The Human Side: Rediscovering Empathy

At the end of the day, nobody wants to give product feedback to a chatbot. They want to be *heard* by another human being who can empathize — someone who can listen to the frustration behind their words, sense the emotion between the lines, and connect it to the broader picture of what the product is trying to achieve.

That’s where we fit in.

Empathy is what transforms a set of requirements into a real solution. It’s what allows us to see that a customer’s complaint about “too many clicks” is actually about *feeling overwhelmed* in a workflow. It’s what helps us mediate trade-offs — not between features, but between *human needs*.

AI can model behavior. It can predict churn. But it can’t truly *care*.

And in a world where users are increasingly surrounded by algorithms, that simple human ability — to care, to interpret, to connect — becomes our superpower.

---

## The Emotional Craft of Product

In many ways, this shift back to empathy is a return to our roots. The best product managers have always been storytellers, diplomats, therapists, and translators. We’ve always sat in the middle — not just between teams, but between *human realities*.

The future of our craft will double down on that. We’ll need to:

- **Build trust** in systems that users don’t fully understand.  
- **Balance automation and agency**, ensuring technology empowers rather than replaces.  
- **Translate emotion into design**, helping teams see beyond data points to lived experiences.

This is not about being “softer” PMs. It’s about being *truer* ones — expanding our empathy from the surface level of user research to the systemic level of how people experience AI in their lives.

---

## The Next Artistry

Julie wrote:

> “The engineer who hand-optimized code for elegance can now obsess over architecting systems of elegance; the writer who agonized over every word choice can now agonize over prompt engineering precision.”

So what about us?

Maybe the product manager who once obsessed over Jira tickets will now obsess over *how technology and humanity learn from each other*.

Maybe our new artistry is not in managing backlogs, but in *designing relationships* — between humans, systems, and the values that connect them.

Because at its core, product management has never been about documents, metrics, or rituals. It’s about *understanding people*. And in this new era, that understanding will matter more than ever.

Our craft isn’t disappearing; it’s evolving.  
We’re not just building products anymore — we’re building empathy into the systems that will shape how people live, work, and dream.

---

## A Personal Example: When Empathy Meets Product Judgment

In my world of **digital evidence management**, empathy isn’t just a nice-to-have — it’s mission-critical.

Cops don’t watch video evidence for entertainment. They watch it to investigate crimes, to uncover truth, and ultimately to put the bad guys in jail faster. If we don’t truly understand *these humans* and their jobs, we’ll make grave mistakes by copying what works in consumer products like YouTube.

For example, imagine if we blindly borrowed YouTube’s playbook:

- **Social features — comments, likes, shares.** These engagement mechanisms have no place in a legal system. Evidence must be secure, isolated, and objective — not subject to popularity metrics or public opinion.  
- **Easy editing tools.** YouTube provides creators with ways to trim, zoom, or add effects. A digital evidence management system (DEMS), on the other hand, must preserve the original file and maintain a complete audit trail of every interaction. Only non-destructive actions like annotations, redactions, or analysis on a secure copy are allowed.  
- **Trending or recommendation algorithms.** In the consumer world, popularity drives discovery. In law enforcement, discovery must follow strict case IDs, metadata, and access permissions — *not* trending patterns or personal preferences.

If we fail to empathize with the reality of police work, we risk building features that look impressive in a demo but are utterly useless — or worse, dangerous — in practice.

On the other hand, when we start with empathy, we see opportunities that truly matter.  

![AI highlights of key moments](/assets/key-moments.png)

Cops don’t need “likes.” What they *do* need is help finding the critical few seconds in hours of footage — the moment a firearm was unholstered, a TASER discharged, or someone said, “I can’t breathe.”  

That’s the kind of problem I’m working on — using AI to surface truth faster, while keeping the integrity of evidence intact. It’s not glamorous, but it’s deeply human work.  

Because at the end of the day, empathy is what keeps us focused on solving *real* problems for *real* people.


---

## Author’s Note

If this resonates with you, you’re probably someone who still believes that technology should make us *more human*, not less.  

AI will keep getting better at execution — but empathy, curiosity, and judgment will always be ours to cultivate.  

If you’re a fellow product manager exploring how AI is reshaping our craft, I’d love to hear your perspective. How do you see empathy evolving in your work?  

You can reach me on [LinkedIn](https://www.linkedin.com/) or drop me a note at [thucldnguyen.com](https://www.thucldnguyen.com/). Let’s keep the conversation going.
